{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                   my lab      my desktop      my notebook\n",
    "import torch                        # 1.13.1\n",
    "import torchvision                  # 0.14.1\n",
    "import numpy as np                  # 1.23.5\n",
    "import tqdm                         # 4.64.1\n",
    "import matplotlib.pyplot as plt     # 3.6.3\n",
    "import PIL.Image as Image           # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fortorch.dataset import *\n",
    "from fortorch.metrix import *\n",
    "from utills.utills import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms as trans\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "def get_train_dataset(imgs_folder):\n",
    "    train_transform = trans.Compose([\n",
    "        trans.RandomHorizontalFlip(),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    ds = ImageFolder(imgs_folder, train_transform)\n",
    "    class_num = ds[-1][1] + 1 # tuple[tensor, label] label + 1\n",
    "    return ds, class_num\n",
    "\n",
    "data_path = [r\"C:\\Users\\asiclab06\\Datasets\\faces_vgg_112x112\\imgs\" ,Path(os.getcwd())/'sample_data'][0] \n",
    "ds, cls_n = get_train_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8631, 3, 8628)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# def get_split_dataset(imgs_foldder,head_n):\n",
    "class SplitImageFolder(Dataset):\n",
    "    def __init__(self,root,n) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n = n\n",
    "        self.ds, self.class_num = get_train_dataset(root)\n",
    "        self.val_ds,self.val_label = None, None\n",
    "        self.train_ds,self.train_label = np.array([]),np.array([])\n",
    "\n",
    "        for i,(img, label) in enumerate(ds.imgs): # path,label\n",
    "            if label == n:\n",
    "                self.train_ds = np.append(self.train_ds,img)\n",
    "                self.train_label = np.append(self.train_label,label)\n",
    "            else:\n",
    "                self.val_ds = np.append(self.val_ds,img)\n",
    "                self.val_label = np.append(self.val_label,label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return  \n",
    "    \n",
    "    def __len__(self):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\asiclab06\\\\Datasets\\\\faces_vgg_112x112\\\\imgs\\\\0\\\\1.jpg', 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.imgs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c12c419fb877effd9e13c85f1b267b5ef22e851a6af2e6405c99ea71c0dd76c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
